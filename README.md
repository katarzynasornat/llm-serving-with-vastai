# llm-serving-with-vastai
This repository contains some code and notes on how to serve example LLM model with vast.ai/runpod.ai for some number of customers and testing throughput
